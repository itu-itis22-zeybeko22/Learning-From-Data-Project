{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:55.781525Z",
     "start_time": "2024-05-26T13:24:50.877663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "74e6031f164e173d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:55.786413Z",
     "start_time": "2024-05-26T13:24:55.782035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Declaring Transforms (Resize and normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ],
   "id": "d7205c488084c4d2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:55.797898Z",
     "start_time": "2024-05-26T13:24:55.787419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Training images\n",
    "trainset = torchvision.datasets.ImageFolder(root=r'C:\\Users\\omerf\\OneDrive\\Masa端st端\\Learning From Data Project\\classes_train', transform=transform)\n",
    "#Loading train images\n",
    "loader_train = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=8)"
   ],
   "id": "aff2a1a0fee7b63c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:55.808390Z",
     "start_time": "2024-05-26T13:24:55.798410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Test images\n",
    "testset = torchvision.datasets.ImageFolder(root=r'C:\\Users\\omerf\\OneDrive\\Masa端st端\\Learning From Data Project\\classes_test', transform=transform)\n",
    "#Loading test images\n",
    "loader_test = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)"
   ],
   "id": "b61ff0931f84948f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Loading ResNet18-Model\n",
    "resnet = models.resnet18(pretrained=True)"
   ],
   "id": "28ccd9feab07ddb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:56.071054Z",
     "start_time": "2024-05-26T13:24:56.065072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Creating a class Embedding Model to distinguish positive and negative samples\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, base_model, embedding_size):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.base_model = nn.Sequential(*list(base_model.children())[:-1])  # Remove the last fully connected layer\n",
    "        self.fc = nn.Linear(base_model.fc.in_features, embedding_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ],
   "id": "74ad85e7023ebd1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:56.080193Z",
     "start_time": "2024-05-26T13:24:56.072165Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_resnet = EmbeddingModel(resnet, embedding_size=128).to(device)",
   "id": "392fcdd7d7edf206",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:56.085687Z",
     "start_time": "2024-05-26T13:24:56.081201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Creating a class ContrastiveLoss to promote the attraction of similar pairs together (positive samples) and the removal of dissimilar pairs (negative samples)\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) + label * \n",
    "                                      torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ],
   "id": "ab99f2a2616cf74b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:56.090839Z",
     "start_time": "2024-05-26T13:24:56.086815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Defining contrastive loss and optimizer\n",
    "criterion_contrastive = ContrastiveLoss()\n",
    "optimizer_contrastive = optim.Adam(embedding_resnet.parameters(), lr=0.0001)"
   ],
   "id": "901f0973a32c51c4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:24:56.098912Z",
     "start_time": "2024-05-26T13:24:56.091847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Function to create positive and negative pairs\n",
    "def create_pairs(images, labels, num_pairs=16):\n",
    "    pairs = []\n",
    "    labels_list = labels.tolist()\n",
    "    unique_labels = list(set(labels_list))\n",
    "    \n",
    "    for _ in range(num_pairs):\n",
    "        #Positive pair\n",
    "        pos_label = random.choice(unique_labels)\n",
    "        pos_indices = [i for i, label in enumerate(labels_list) if label == pos_label]\n",
    "        if len(pos_indices) > 1:\n",
    "            i, j = random.sample(pos_indices, 2)\n",
    "            pairs.append((images[i].unsqueeze(0), images[j].unsqueeze(0), torch.tensor([1.0], device=device)))\n",
    "        \n",
    "        #Negative pair\n",
    "        neg_label1, neg_label2 = random.sample(unique_labels, 2)\n",
    "        neg_index1 = random.choice([i for i, label in enumerate(labels_list) if label == neg_label1])\n",
    "        neg_index2 = random.choice([i for i, label in enumerate(labels_list) if label == neg_label2])\n",
    "        pairs.append((images[neg_index1].unsqueeze(0), images[neg_index2].unsqueeze(0), torch.tensor([0.0], device=device)))\n",
    "    \n",
    "    return pairs"
   ],
   "id": "1776e954766021f5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-26T13:24:56.099919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Training loop for the contrastive loss\n",
    "losses = []\n",
    "num_epochs_contrastive = 10\n",
    "for epoch in range(num_epochs_contrastive):\n",
    "    embedding_resnet.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader_train:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        pairs = create_pairs(images, labels, num_pairs=16)\n",
    "        for img1, img2, label in pairs:\n",
    "            optimizer_contrastive.zero_grad()\n",
    "            \n",
    "            output1 = embedding_resnet(img1)\n",
    "            output2 = embedding_resnet(img2)\n",
    "            \n",
    "            loss = criterion_contrastive(output1, output2, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer_contrastive.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(loader_train)\n",
    "    print(f\"Epoch: {epoch}, Contrastive Loss: {avg_loss}\")\n",
    "    losses.append(avg_loss)"
   ],
   "id": "fbfdefff4206c175",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sns.lineplot(x=range(len(losses)), y=losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Loss Change in Every Epoch\")\n",
    "plt.show()"
   ],
   "id": "eda9fd9565de8b87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#Adding linear classifier on top of the Embedding Model\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=128, out_features=512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=512, out_features=10)\n",
    ")\n",
    "\n",
    "embedding_resnet.fc = classifier.to(device)"
   ],
   "id": "27a7b2db7c862511",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#Freezing ResNet-18 Params\n",
    "for param in embedding_resnet.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Defining loss function and optimizer for the classifier\n",
    "criterion_classifier = nn.CrossEntropyLoss()\n",
    "optimizer_classifier = optim.Adam(embedding_resnet.fc.parameters(), lr=0.001)"
   ],
   "id": "47f3b3340e774bdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#Training with classifier\n",
    "loss1 = []\n",
    "accuracy = []\n",
    "num_epochs_classifier = 10\n",
    "for epoch in range(num_epochs_classifier):\n",
    "    embedding_resnet.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader_train:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer_classifier.zero_grad()\n",
    "        \n",
    "        outputs = embedding_resnet(images)\n",
    "        loss = criterion_classifier(outputs, labels)\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer_classifier.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(loader_train)\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Epoch: {epoch}, Loss: {avg_loss}, Accuracy: {acc}%\")\n",
    "    loss1.append(avg_loss)\n",
    "    accuracy.append(acc)"
   ],
   "id": "df327fcb00bf287b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sns.lineplot(x=range(len(loss1)), y=loss1)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Classifier Loss Change in Every Epoch\")\n",
    "plt.show()"
   ],
   "id": "d7124a0247b802e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sns.lineplot(x=range(len(accuracy)), y=accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Classifier Accuracy Change in Every Epoch\")\n",
    "plt.show()"
   ],
   "id": "8e0938d26314e86f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
